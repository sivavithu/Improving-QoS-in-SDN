{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivavithu/Improving-QoS-in-SDN/blob/main/RF6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXwztfwZa38v",
        "outputId": "accc8b11-fe44-4ef2-de03-1a4424c749b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_VKmBjLcMrg",
        "outputId": "5233a2fb-5b2b-4fa5-b8a8-9e8356fcce16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Enhanced CIC-Darknet2020 Application Classifier\n",
            "Target: 95%+ Accuracy for SDN Application Classification\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\"üöÄ Enhanced CIC-Darknet2020 Application Classifier\")\n",
        "print(\"Target: 95%+ Accuracy for SDN Application Classification\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhBkdYCvceLL",
        "outputId": "6d049619-ed89-46f9-b542-6d660a11a02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "‚úÖ Additional libraries installed!\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 2: Install Additional Libraries\n",
        "# ===============================================================================\n",
        "\n",
        "# Install required libraries\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "print(\"‚úÖ Additional libraries installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqRBmCiicjHw",
        "outputId": "d8e1d844-1e45-4e1d-c398-0b0a0a3a55c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All ML libraries imported!\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 3: Import ML Libraries\n",
        "# ===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE, RFECV\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                           precision_recall_fscore_support)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "print(\"‚úÖ All ML libraries imported!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "mjR3eImlctNz",
        "outputId": "acea7600-0968-4edd-cb59-e750f1fe2671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Dataset Shape: (158616, 85)\n",
            "üìä Memory Usage: 155.32 MB\n",
            "\n",
            "üìã Dataset Info:\n",
            "  Rows: 158,616\n",
            "  Columns: 85\n",
            "  Missing values: 48\n",
            "\n",
            "üìù First 5 rows:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b3f094b8-8e43-41cc-a1ea-656c733f954c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow ID</th>\n",
              "      <th>Src IP</th>\n",
              "      <th>Src Port</th>\n",
              "      <th>Dst IP</th>\n",
              "      <th>Dst Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packet</th>\n",
              "      <th>Total Bwd packets</th>\n",
              "      <th>...</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.152.152.11-216.58.220.99-57158-443-6</td>\n",
              "      <td>10.152.152.11</td>\n",
              "      <td>57158</td>\n",
              "      <td>216.58.220.99</td>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>24/07/2015 04:09:48 PM</td>\n",
              "      <td>229</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>Non-Tor</td>\n",
              "      <td>AUDIO-STREAMING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.152.152.11-216.58.220.99-57159-443-6</td>\n",
              "      <td>10.152.152.11</td>\n",
              "      <td>57159</td>\n",
              "      <td>216.58.220.99</td>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>24/07/2015 04:09:48 PM</td>\n",
              "      <td>407</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>Non-Tor</td>\n",
              "      <td>AUDIO-STREAMING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.152.152.11-216.58.220.99-57160-443-6</td>\n",
              "      <td>10.152.152.11</td>\n",
              "      <td>57160</td>\n",
              "      <td>216.58.220.99</td>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>24/07/2015 04:09:48 PM</td>\n",
              "      <td>431</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>Non-Tor</td>\n",
              "      <td>AUDIO-STREAMING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.152.152.11-74.125.136.120-49134-443-6</td>\n",
              "      <td>10.152.152.11</td>\n",
              "      <td>49134</td>\n",
              "      <td>74.125.136.120</td>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>24/07/2015 04:09:48 PM</td>\n",
              "      <td>359</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>Non-Tor</td>\n",
              "      <td>AUDIO-STREAMING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.152.152.11-173.194.65.127-34697-19305-6</td>\n",
              "      <td>10.152.152.11</td>\n",
              "      <td>34697</td>\n",
              "      <td>173.194.65.127</td>\n",
              "      <td>19305</td>\n",
              "      <td>6</td>\n",
              "      <td>24/07/2015 04:09:45 PM</td>\n",
              "      <td>10778451</td>\n",
              "      <td>591</td>\n",
              "      <td>400</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.437765e+15</td>\n",
              "      <td>3.117718e+06</td>\n",
              "      <td>1.437765e+15</td>\n",
              "      <td>1.437765e+15</td>\n",
              "      <td>Non-Tor</td>\n",
              "      <td>AUDIO-STREAMING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3f094b8-8e43-41cc-a1ea-656c733f954c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3f094b8-8e43-41cc-a1ea-656c733f954c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3f094b8-8e43-41cc-a1ea-656c733f954c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8af72628-6a25-4469-a0fe-6455c0bf76fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8af72628-6a25-4469-a0fe-6455c0bf76fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8af72628-6a25-4469-a0fe-6455c0bf76fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                      Flow ID         Src IP  Src Port  \\\n",
              "0     10.152.152.11-216.58.220.99-57158-443-6  10.152.152.11     57158   \n",
              "1     10.152.152.11-216.58.220.99-57159-443-6  10.152.152.11     57159   \n",
              "2     10.152.152.11-216.58.220.99-57160-443-6  10.152.152.11     57160   \n",
              "3    10.152.152.11-74.125.136.120-49134-443-6  10.152.152.11     49134   \n",
              "4  10.152.152.11-173.194.65.127-34697-19305-6  10.152.152.11     34697   \n",
              "\n",
              "           Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n",
              "0   216.58.220.99       443         6  24/07/2015 04:09:48 PM            229   \n",
              "1   216.58.220.99       443         6  24/07/2015 04:09:48 PM            407   \n",
              "2   216.58.220.99       443         6  24/07/2015 04:09:48 PM            431   \n",
              "3  74.125.136.120       443         6  24/07/2015 04:09:48 PM            359   \n",
              "4  173.194.65.127     19305         6  24/07/2015 04:09:45 PM       10778451   \n",
              "\n",
              "   Total Fwd Packet  Total Bwd packets  ...  Active Mean  Active Std  \\\n",
              "0                 1                  1  ...            0           0   \n",
              "1                 1                  1  ...            0           0   \n",
              "2                 1                  1  ...            0           0   \n",
              "3                 1                  1  ...            0           0   \n",
              "4               591                400  ...            0           0   \n",
              "\n",
              "   Active Max  Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
              "0           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "1           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "2           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "3           0           0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "4           0           0  1.437765e+15  3.117718e+06  1.437765e+15   \n",
              "\n",
              "       Idle Min    Label          Label.1  \n",
              "0  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
              "1  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
              "2  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
              "3  0.000000e+00  Non-Tor  AUDIO-STREAMING  \n",
              "4  1.437765e+15  Non-Tor  AUDIO-STREAMING  \n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 4: Load and Inspect Dataset\n",
        "# ===============================================================================\n",
        "\n",
        "# Load your dataset - UPDATE THIS PATH\n",
        "df = pd.read_csv('/content/drive/MyDrive/Research/Darknet.CSV')\n",
        "\n",
        "print(f\"üìä Dataset Shape: {df.shape}\")\n",
        "print(f\"üìä Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"\\nüìã Dataset Info:\")\n",
        "print(f\"  Rows: {len(df):,}\")\n",
        "print(f\"  Columns: {len(df.columns)}\")\n",
        "print(f\"  Missing values: {df.isnull().sum().sum():,}\")\n",
        "\n",
        "# Show first few rows\n",
        "print(\"\\nüìù First 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN9vxhX2c9on",
        "outputId": "4cc57d85-04f5-4c20-8553-a130533cddfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç SEARCHING FOR APPLICATION COLUMN\n",
            "========================================\n",
            "\n",
            "üìä Column: 'Flow ID' (79160 unique values)\n",
            "   Sample values: ['10.152.152.11-216.58.220.99-57158-443-6', '10.152.152.11-216.58.220.99-57159-443-6', '10.152.152.11-216.58.220.99-57160-443-6', '10.152.152.11-74.125.136.120-49134-443-6', '10.152.152.11-173.194.65.127-34697-19305-6']\n",
            "   ‚ùå Unlikely application column (score: 0)\n",
            "\n",
            "üìä Column: 'Src IP' (4026 unique values)\n",
            "   Sample values: ['10.152.152.11', '173.194.33.97', '74.125.28.189', '74.125.228.199', '173.194.65.100']\n",
            "   ‚ùå Unlikely application column (score: 0)\n",
            "\n",
            "üìä Column: 'Dst IP' (7553 unique values)\n",
            "   Sample values: ['216.58.220.99', '74.125.136.120', '173.194.65.127', '10.152.152.11', '216.58.216.142']\n",
            "   ‚ùå Unlikely application column (score: 0)\n",
            "\n",
            "üìä Column: 'Timestamp' (34836 unique values)\n",
            "   Sample values: ['24/07/2015 04:09:48 PM', '24/07/2015 04:09:45 PM', '24/07/2015 04:10:00 PM', '24/07/2015 04:09:46 PM', '24/07/2015 04:09:49 PM']\n",
            "   ‚ùå Unlikely application column (score: 0)\n",
            "\n",
            "üìä Column: 'Label' (4 unique values)\n",
            "   Sample values: ['Non-Tor', 'NonVPN', 'Tor', 'VPN']\n",
            "   ‚ùå Unlikely application column (score: 0)\n",
            "\n",
            "üìä Column: 'Label.1' (11 unique values)\n",
            "   Sample values: ['AUDIO-STREAMING', 'Chat', 'Audio-Streaming', 'Browsing', 'Email']\n",
            "   ‚úÖ STRONG application candidate (score: 10)\n",
            "\n",
            "üéØ SELECTED: 'Label.1' (score: 10)\n",
            "\n",
            "‚úÖ Using column: 'Label.1'\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 5: Find Application Column\n",
        "# ===============================================================================\n",
        "\n",
        "def find_application_column_enhanced(df):\n",
        "    \"\"\"Find the correct application classification column\"\"\"\n",
        "\n",
        "    print(\"üîç SEARCHING FOR APPLICATION COLUMN\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Check all object columns\n",
        "    object_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "    app_candidates = []\n",
        "\n",
        "    for col in object_columns:\n",
        "        unique_vals = df[col].unique()\n",
        "        sample_text = ' '.join([str(v).lower() for v in unique_vals[:10]])\n",
        "\n",
        "        print(f\"\\nüìä Column: '{col}' ({len(unique_vals)} unique values)\")\n",
        "        print(f\"   Sample values: {list(unique_vals[:5])}\")\n",
        "\n",
        "        # Enhanced application detection\n",
        "        app_keywords = ['browsing', 'chat', 'email', 'audio', 'video', 'voip',\n",
        "                       'p2p', 'stream', 'web', 'http', 'ftp', 'torrent']\n",
        "\n",
        "        keyword_matches = sum(1 for keyword in app_keywords if keyword in sample_text)\n",
        "\n",
        "        # Check for application patterns\n",
        "        has_streaming = 'stream' in sample_text\n",
        "        has_protocols = any(p in sample_text for p in ['http', 'ftp', 'smtp'])\n",
        "        reasonable_classes = 5 <= len(unique_vals) <= 25\n",
        "\n",
        "        score = keyword_matches\n",
        "        if has_streaming: score += 2\n",
        "        if has_protocols: score += 1\n",
        "        if reasonable_classes: score += 1\n",
        "\n",
        "        app_candidates.append((col, score, len(unique_vals)))\n",
        "\n",
        "        if score >= 3:\n",
        "            print(f\"   ‚úÖ STRONG application candidate (score: {score})\")\n",
        "        elif score >= 1:\n",
        "            print(f\"   ‚ö†Ô∏è Possible application column (score: {score})\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Unlikely application column (score: {score})\")\n",
        "\n",
        "    # Sort by score\n",
        "    app_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    if app_candidates and app_candidates[0][1] > 0:\n",
        "        best_col = app_candidates[0][0]\n",
        "        print(f\"\\nüéØ SELECTED: '{best_col}' (score: {app_candidates[0][1]})\")\n",
        "        return best_col\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No clear application column found!\")\n",
        "        return object_columns[0] if len(object_columns) > 0 else df.columns[-1]\n",
        "\n",
        "# Find application column\n",
        "app_column = find_application_column_enhanced(df)\n",
        "print(f\"\\n‚úÖ Using column: '{app_column}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHb1y0ZIdDyL",
        "outputId": "e95b15a6-ace4-4f7a-b29b-4a2942d169a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ APPLICATION ANALYSIS\n",
            "=========================\n",
            "Application Column: 'Label.1'\n",
            "Number of Applications: 11\n",
            "\n",
            "üìä Application Distribution:\n",
            "   1. P2P                            48,520 ( 30.6%)\n",
            "   2. Browsing                       46,457 ( 29.3%)\n",
            "   3. Audio-Streaming                19,830 ( 12.5%)\n",
            "   4. Chat                           11,629 (  7.3%)\n",
            "   5. File-Transfer                  11,098 (  7.0%)\n",
            "   6. Video-Streaming                 9,486 (  6.0%)\n",
            "   7. Email                           6,145 (  3.9%)\n",
            "   8. VOIP                            3,566 (  2.2%)\n",
            "   9. AUDIO-STREAMING                 1,520 (  1.0%)\n",
            "  10. Video-streaming                   281 (  0.2%)\n",
            "  11. File-transfer                      84 (  0.1%)\n",
            "‚úÖ Good for classification: 11 classes\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 6: Analyze Application Distribution\n",
        "# ===============================================================================\n",
        "\n",
        "# Analyze the selected application column\n",
        "y_raw = df[app_column].copy()\n",
        "app_distribution = y_raw.value_counts()\n",
        "\n",
        "print(f\"üéØ APPLICATION ANALYSIS\")\n",
        "print(\"=\" * 25)\n",
        "print(f\"Application Column: '{app_column}'\")\n",
        "print(f\"Number of Applications: {len(app_distribution)}\")\n",
        "\n",
        "print(f\"\\nüìä Application Distribution:\")\n",
        "for i, (app, count) in enumerate(app_distribution.items()):\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"  {i+1:2d}. {app:<30} {count:6,} ({percentage:5.1f}%)\")\n",
        "\n",
        "# Check if suitable for classification\n",
        "if len(app_distribution) < 2:\n",
        "    print(\"‚ùå ERROR: Need at least 2 classes for classification!\")\n",
        "elif len(app_distribution) > 50:\n",
        "    print(\"‚ö†Ô∏è WARNING: Too many classes, might affect performance\")\n",
        "else:\n",
        "    print(f\"‚úÖ Good for classification: {len(app_distribution)} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbZgcWsodSND",
        "outputId": "f2c94a77-0036-4722-ae1e-bef42e8ed331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß ENHANCED DATA PREPROCESSING\n",
            "===================================\n",
            "Initial: 84 features, 158616 samples\n",
            "üóëÔ∏è Removed SDN-incompatible: ['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Timestamp']\n",
            "üóëÔ∏è Removed label column: Label\n",
            "üîÑ Handling infinite values...\n",
            "üóëÔ∏è Removed 15 constant columns\n",
            "üìÑ Removed 56244 duplicates\n",
            "‚úÖ Final: 62 features, 102372 samples\n",
            "üè∑Ô∏è LABEL ENCODING RESULTS\n",
            "============================\n",
            "Number of classes: 11\n",
            "\n",
            "üìä Encoded Class Distribution:\n",
            "   0. AUDIO-STREAMING            1,438 samples (  1.4%)\n",
            "   1. Audio-Streaming           12,055 samples ( 11.8%)\n",
            "   2. Browsing                  29,803 samples ( 29.1%)\n",
            "   3. Chat                       9,654 samples (  9.4%)\n",
            "   4. Email                      5,313 samples (  5.2%)\n",
            "   5. File-Transfer             10,402 samples ( 10.2%)\n",
            "   6. File-transfer                 72 samples (  0.1%)\n",
            "   7. P2P                       23,233 samples ( 22.7%)\n",
            "   8. VOIP                       1,930 samples (  1.9%)\n",
            "   9. Video-Streaming            8,235 samples (  8.0%)\n",
            "  10. Video-streaming              237 samples (  0.2%)\n",
            "\n",
            "üìà Class imbalance ratio: 413.93\n",
            "‚ö†Ô∏è HIGH imbalance - will apply advanced balancing\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 7: Data Preprocessing\n",
        "# ===============================================================================\n",
        "\n",
        "def preprocess_data_enhanced(df, target_col):\n",
        "    \"\"\"Enhanced data preprocessing for maximum accuracy\"\"\"\n",
        "\n",
        "    print(\"üîß ENHANCED DATA PREPROCESSING\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_col]).copy()\n",
        "    y = df[target_col].copy()\n",
        "\n",
        "    print(f\"Initial: {X.shape[1]} features, {len(X)} samples\")\n",
        "\n",
        "    # Remove ID and network-specific columns (not available in SDN)\n",
        "    sdn_incompatible = [\n",
        "        'Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Timestamp',\n",
        "        'flow_id', 'src_ip', 'dst_ip', 'src_port', 'dst_port', 'timestamp',\n",
        "        'FlowID', 'SrcIP', 'DstIP', 'SrcPort', 'DstPort', 'Flow_ID'\n",
        "    ]\n",
        "\n",
        "    removed_cols = []\n",
        "    for col in sdn_incompatible:\n",
        "        if col in X.columns:\n",
        "            X = X.drop(columns=[col])\n",
        "            removed_cols.append(col)\n",
        "\n",
        "    if removed_cols:\n",
        "        print(f\"üóëÔ∏è Removed SDN-incompatible: {removed_cols}\")\n",
        "\n",
        "    # Remove other label columns\n",
        "    other_labels = ['Label', 'label', 'class', 'Class', 'Attack', 'attack']\n",
        "    for col in list(X.columns):\n",
        "        if any(label in col for label in other_labels):\n",
        "            X = X.drop(columns=[col])\n",
        "            print(f\"üóëÔ∏è Removed label column: {col}\")\n",
        "\n",
        "    # Convert object columns to numeric\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == 'object':\n",
        "            try:\n",
        "                X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "            except:\n",
        "                le = LabelEncoder()\n",
        "                X[col] = le.fit_transform(X[col].astype(str))\n",
        "                print(f\"üî§ Label encoded: {col}\")\n",
        "\n",
        "    # Handle infinite values\n",
        "    print(\"üîÑ Handling infinite values...\")\n",
        "    X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Remove high missing columns (>85% missing)\n",
        "    missing_thresh = 0.85\n",
        "    high_missing = X.columns[X.isnull().sum() / len(X) > missing_thresh]\n",
        "    if len(high_missing) > 0:\n",
        "        X = X.drop(columns=high_missing)\n",
        "        print(f\"üóëÔ∏è Removed {len(high_missing)} high-missing columns\")\n",
        "\n",
        "    # Remove constant columns\n",
        "    constant_cols = []\n",
        "    for col in X.columns:\n",
        "        if X[col].nunique() <= 1:\n",
        "            constant_cols.append(col)\n",
        "\n",
        "    if constant_cols:\n",
        "        X = X.drop(columns=constant_cols)\n",
        "        print(f\"üóëÔ∏è Removed {len(constant_cols)} constant columns\")\n",
        "\n",
        "    # Smart missing value imputation\n",
        "    for col in X.columns:\n",
        "        if X[col].isnull().sum() > 0:\n",
        "            if abs(X[col].skew()) > 1:  # Skewed data\n",
        "                X[col] = X[col].fillna(X[col].median())\n",
        "            else:  # Normal data\n",
        "                X[col] = X[col].fillna(X[col].mean())\n",
        "\n",
        "    # Remove duplicates\n",
        "    before_dedup = len(X)\n",
        "    duplicated = X.duplicated()\n",
        "    X = X[~duplicated]\n",
        "    y = y[~duplicated]\n",
        "    after_dedup = len(X)\n",
        "\n",
        "    if before_dedup != after_dedup:\n",
        "        print(f\"üìÑ Removed {before_dedup - after_dedup} duplicates\")\n",
        "\n",
        "    print(f\"‚úÖ Final: {X.shape[1]} features, {len(X)} samples\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Apply preprocessing\n",
        "X_clean, y_clean = preprocess_data_enhanced(df, app_column)\n",
        "\n",
        "# ===============================================================================\n",
        "# CELL 8: Label Encoding and Analysis\n",
        "# ===============================================================================\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_clean)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "print(\"üè∑Ô∏è LABEL ENCODING RESULTS\")\n",
        "print(\"=\" * 28)\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "\n",
        "# Show class distribution\n",
        "unique_classes, class_counts = np.unique(y_encoded, return_counts=True)\n",
        "print(f\"\\nüìä Encoded Class Distribution:\")\n",
        "for i, (cls, count) in enumerate(zip(class_names, class_counts)):\n",
        "    print(f\"  {i:2d}. {cls:<25} {count:6,} samples ({count/len(y_encoded)*100:5.1f}%)\")\n",
        "\n",
        "# Calculate class imbalance\n",
        "imbalance_ratio = max(class_counts) / min(class_counts)\n",
        "print(f\"\\nüìà Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "\n",
        "if imbalance_ratio > 10:\n",
        "    print(\"‚ö†Ô∏è HIGH imbalance - will apply advanced balancing\")\n",
        "elif imbalance_ratio > 3:\n",
        "    print(\"‚ö†Ô∏è MODERATE imbalance - will apply balancing\")\n",
        "else:\n",
        "    print(\"‚úÖ Classes reasonably balanced\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Nnf80sd37m",
        "outputId": "570188c3-67b2-4acb-83f7-18b8df544cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è FEATURE ENGINEERING\n",
            "=======================\n",
            "Creating statistical features...\n",
            "Creating ratio features from 32 flow columns...\n",
            "‚úÖ Added 11 engineered features\n",
            "üìä Total features: 73\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 9: Feature Engineering\n",
        "# ===============================================================================\n",
        "\n",
        "def create_advanced_features(X):\n",
        "    \"\"\"Create engineered features for better classification\"\"\"\n",
        "\n",
        "    print(\"‚öôÔ∏è FEATURE ENGINEERING\")\n",
        "    print(\"=\" * 23)\n",
        "\n",
        "    X_eng = X.copy()\n",
        "    initial_count = X_eng.shape[1]\n",
        "\n",
        "    # Statistical features across all features for each sample\n",
        "    print(\"Creating statistical features...\")\n",
        "    X_eng['row_sum'] = X_eng.sum(axis=1)\n",
        "    X_eng['row_mean'] = X_eng.mean(axis=1)\n",
        "    X_eng['row_std'] = X_eng.std(axis=1)\n",
        "    X_eng['row_max'] = X_eng.max(axis=1)\n",
        "    X_eng['row_min'] = X_eng.min(axis=1)\n",
        "    X_eng['row_range'] = X_eng['row_max'] - X_eng['row_min']\n",
        "    X_eng['row_median'] = X_eng.median(axis=1)\n",
        "\n",
        "    # Network flow specific features\n",
        "    flow_keywords = ['byte', 'packet', 'length', 'duration', 'rate', 'time']\n",
        "    flow_cols = [col for col in X.columns if any(kw in col.lower() for kw in flow_keywords)]\n",
        "\n",
        "    if len(flow_cols) >= 4:\n",
        "        print(f\"Creating ratio features from {len(flow_cols)} flow columns...\")\n",
        "\n",
        "        # Create meaningful ratios\n",
        "        for i in range(0, min(len(flow_cols), 8), 2):\n",
        "            if i+1 < len(flow_cols):\n",
        "                col1, col2 = flow_cols[i], flow_cols[i+1]\n",
        "                ratio_name = f'ratio_{i//2}'\n",
        "                X_eng[ratio_name] = X_eng[col1] / (X_eng[col2] + 1e-8)\n",
        "\n",
        "                # Handle infinite ratios\n",
        "                X_eng[ratio_name] = X_eng[ratio_name].replace([np.inf, -np.inf], 0)\n",
        "\n",
        "    # Remove any columns that became constant after engineering\n",
        "    for col in X_eng.columns:\n",
        "        if X_eng[col].nunique() <= 1:\n",
        "            X_eng = X_eng.drop(columns=[col])\n",
        "\n",
        "    new_features = X_eng.shape[1] - initial_count\n",
        "    print(f\"‚úÖ Added {new_features} engineered features\")\n",
        "    print(f\"üìä Total features: {X_eng.shape[1]}\")\n",
        "\n",
        "    return X_eng\n",
        "\n",
        "# Apply feature engineering\n",
        "X_engineered = create_advanced_features(X_clean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFA6lL-5d5d6",
        "outputId": "ae201967-ea7e-4a9e-9c2c-093da8b2dee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ ADVANCED FEATURE SELECTION\n",
            "Target: 80 features\n",
            "================================\n",
            "Stage 1: Correlation filtering...\n",
            "  Removed 17 highly correlated features\n",
            "Stage 2: Univariate selection...\n",
            "  Selected 56 features\n",
            "Stage 3: Recursive elimination...\n",
            "  RFECV selected 45 optimal features\n",
            "Stage 4: Importance-based selection...\n",
            "‚úÖ Final selection: 45 features\n",
            "\n",
            "üèÜ Top 10 Selected Features:\n",
            "   1. Idle Mean                 (0.0877)\n",
            "   2. Idle Min                  (0.0875)\n",
            "   3. FWD Init Win Bytes        (0.0479)\n",
            "   4. Flow IAT Max              (0.0437)\n",
            "   5. Flow IAT Min              (0.0402)\n",
            "   6. Bwd Init Win Bytes        (0.0364)\n",
            "   7. ratio_0                   (0.0355)\n",
            "   8. Fwd Packets/s             (0.0343)\n",
            "   9. Flow Duration             (0.0341)\n",
            "  10. Flow IAT Mean             (0.0330)\n",
            "\n",
            "‚úÖ Feature selection completed!\n",
            "üìä Selected 45 features from 73 original features\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 10: Advanced Feature Selection\n",
        "# ===============================================================================\n",
        "\n",
        "def select_best_features(X, y, target_features=80):\n",
        "    \"\"\"Multi-stage feature selection for optimal performance\"\"\"\n",
        "\n",
        "    print(f\"üéØ ADVANCED FEATURE SELECTION\")\n",
        "    print(f\"Target: {target_features} features\")\n",
        "    print(\"=\" * 32)\n",
        "\n",
        "    # Stage 1: Remove highly correlated features\n",
        "    print(\"Stage 1: Correlation filtering...\")\n",
        "    corr_matrix = X.corr().abs()\n",
        "\n",
        "    # Find highly correlated pairs\n",
        "    upper_triangle = corr_matrix.where(\n",
        "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
        "    )\n",
        "\n",
        "    high_corr_features = [column for column in upper_triangle.columns\n",
        "                         if any(upper_triangle[column] > 0.95)]\n",
        "\n",
        "    if high_corr_features:\n",
        "        X = X.drop(columns=high_corr_features)\n",
        "        print(f\"  Removed {len(high_corr_features)} highly correlated features\")\n",
        "\n",
        "    # Stage 2: Univariate feature selection\n",
        "    print(\"Stage 2: Univariate selection...\")\n",
        "    k_univariate = min(target_features * 2, X.shape[1])\n",
        "\n",
        "    selector_univariate = SelectKBest(score_func=f_classif, k=k_univariate)\n",
        "    X_univariate = selector_univariate.fit_transform(X, y)\n",
        "    selected_features = X.columns[selector_univariate.get_support()]\n",
        "\n",
        "    print(f\"  Selected {len(selected_features)} features\")\n",
        "\n",
        "    # Stage 3: Recursive Feature Elimination\n",
        "    print(\"Stage 3: Recursive elimination...\")\n",
        "\n",
        "    # Use a fast estimator for RFE\n",
        "    rf_estimator = RandomForestClassifier(\n",
        "        n_estimators=50,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # RFECV with cross-validation\n",
        "    rfecv = RFECV(\n",
        "        estimator=rf_estimator,\n",
        "        step=1,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        min_features_to_select=max(20, target_features//2),\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    X_rfe = rfecv.fit_transform(X_univariate, y)\n",
        "    final_features = selected_features[rfecv.get_support()]\n",
        "\n",
        "    print(f\"  RFECV selected {len(final_features)} optimal features\")\n",
        "\n",
        "    # Stage 4: Final selection based on importance\n",
        "    print(\"Stage 4: Importance-based selection...\")\n",
        "\n",
        "    rf_final = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_final.fit(X_rfe, y)\n",
        "\n",
        "    # Get feature importances\n",
        "    importances = rf_final.feature_importances_\n",
        "\n",
        "    # Select top features\n",
        "    n_final = min(target_features, len(final_features))\n",
        "    top_indices = np.argsort(importances)[-n_final:]\n",
        "\n",
        "    X_final = pd.DataFrame(\n",
        "        X_rfe[:, top_indices],\n",
        "        columns=final_features[top_indices]\n",
        "    )\n",
        "\n",
        "    # Create feature importance dataframe\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'feature': final_features[top_indices],\n",
        "        'importance': importances[top_indices]\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(f\"‚úÖ Final selection: {n_final} features\")\n",
        "\n",
        "    print(f\"\\nüèÜ Top 10 Selected Features:\")\n",
        "    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):\n",
        "        print(f\"  {i+1:2d}. {row['feature']:<25} ({row['importance']:.4f})\")\n",
        "\n",
        "    return X_final, final_features[top_indices], feature_importance_df\n",
        "\n",
        "# Apply feature selection\n",
        "X_selected, selected_feature_names, feature_importance = select_best_features(\n",
        "    X_engineered, y_encoded, target_features=80\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Feature selection completed!\")\n",
        "print(f\"üìä Selected {X_selected.shape[1]} features from {X_engineered.shape[1]} original features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDIfMBMYeUks",
        "outputId": "689d723a-9c09-4ae3-ed61-c6d65de18cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä DATA SPLITTING AND SCALING\n",
            "================================\n",
            "üìà Training set:   71,701 samples (70.0%)\n",
            "üìà Validation set: 15,315 samples (15.0%)\n",
            "üìà Test set:       15,356 samples (15.0%)\n",
            "\n",
            "‚öñÔ∏è Applying RobustScaler...\n",
            "‚úÖ Scaling completed!\n",
            "\n",
            "üîç Data validation:\n",
            "  Training features shape: (71701, 45)\n",
            "  Validation features shape: (15315, 45)\n",
            "  Test features shape: (15356, 45)\n",
            "  No missing values: True\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 11: Data Splitting and Scaling\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"üìä DATA SPLITTING AND SCALING\")\n",
        "print(\"=\" * 32)\n",
        "\n",
        "# Stratified train-test split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_selected, y_encoded,\n",
        "    test_size=0.15,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.176,  # This gives us 70-15-15 split\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"üìà Training set:   {len(X_train):,} samples ({len(X_train)/len(X_selected)*100:.1f}%)\")\n",
        "print(f\"üìà Validation set: {len(X_val):,} samples ({len(X_val)/len(X_selected)*100:.1f}%)\")\n",
        "print(f\"üìà Test set:       {len(X_test):,} samples ({len(X_test)/len(X_selected)*100:.1f}%)\")\n",
        "\n",
        "# Advanced scaling with RobustScaler (handles outliers better)\n",
        "print(\"\\n‚öñÔ∏è Applying RobustScaler...\")\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Scaling completed!\")\n",
        "\n",
        "# Verify no data leakage\n",
        "print(f\"\\nüîç Data validation:\")\n",
        "print(f\"  Training features shape: {X_train_scaled.shape}\")\n",
        "print(f\"  Validation features shape: {X_val_scaled.shape}\")\n",
        "print(f\"  Test features shape: {X_test_scaled.shape}\")\n",
        "print(f\"  No missing values: {not np.isnan(X_train_scaled).any()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ta1X5bDy_Cn",
        "outputId": "dbae6a96-a119-4240-d12f-8ff301574a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öñÔ∏è ADVANCED CLASS BALANCING\n",
            "==============================\n",
            "üìä Current training distribution:\n",
            "  AUDIO-STREAMING           1,007 samples (1.4%)\n",
            "  Audio-Streaming           8,443 samples (11.8%)\n",
            "  Browsing                  20,874 samples (29.1%)\n",
            "  Chat                      6,762 samples (9.4%)\n",
            "  Email                     3,721 samples (5.2%)\n",
            "  File-Transfer             7,286 samples (10.2%)\n",
            "  File-transfer             50 samples (0.1%)\n",
            "  P2P                       16,272 samples (22.7%)\n",
            "  VOIP                      1,352 samples (1.9%)\n",
            "  Video-Streaming           5,768 samples (8.0%)\n",
            "  Video-streaming           166 samples (0.2%)\n",
            "\n",
            "üìà Imbalance ratio: 417.48\n",
            "üîÑ Applying SMOTE + Tomek Links for optimal balancing...\n",
            "üìä After SMOTE + Tomek:\n",
            "  AUDIO-STREAMING           20,389 samples\n",
            "  Audio-Streaming           19,919 samples\n",
            "  Browsing                  19,545 samples\n",
            "  Chat                      18,758 samples\n",
            "  Email                     18,379 samples\n",
            "  File-Transfer             19,692 samples\n",
            "  File-transfer             20,086 samples\n",
            "  P2P                       20,291 samples\n",
            "  VOIP                      18,796 samples\n",
            "  Video-Streaming           19,526 samples\n",
            "  Video-streaming           20,409 samples\n",
            "‚úÖ Balanced dataset: 215,790 samples\n",
            "ü§ñ CREATING OPTIMIZED MODELS\n",
            "==============================\n",
            "Creating Enhanced Random Forest...\n",
            "Creating Extra Trees Classifier...\n",
            "Creating XGBoost Classifier...\n",
            "Creating LightGBM Classifier...\n",
            "‚úÖ Created 4 optimized models\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 12: Class Balancing\n",
        "# ===============================================================================\n",
        "\n",
        "def apply_advanced_balancing(X_train, y_train):\n",
        "    \"\"\"Apply advanced class balancing techniques\"\"\"\n",
        "\n",
        "    print(\"‚öñÔ∏è ADVANCED CLASS BALANCING\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    # Analyze current distribution\n",
        "    unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "\n",
        "    print(\"üìä Current training distribution:\")\n",
        "    for cls, count in zip(unique_train, counts_train):\n",
        "        cls_name = class_names[cls]\n",
        "        print(f\"  {cls_name:<25} {count:,} samples ({count/len(y_train)*100:.1f}%)\")\n",
        "\n",
        "    imbalance_ratio = max(counts_train) / min(counts_train)\n",
        "    print(f\"\\nüìà Imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "\n",
        "    if imbalance_ratio > 5:\n",
        "        print(\"üîÑ Applying SMOTE + Tomek Links for optimal balancing...\")\n",
        "\n",
        "        try:\n",
        "            # SMOTETomek combines oversampling and undersampling\n",
        "            smote_tomek = SMOTETomek(\n",
        "                smote=SMOTE(random_state=RANDOM_STATE, k_neighbors=3),\n",
        "                random_state=RANDOM_STATE\n",
        "            )\n",
        "\n",
        "            X_balanced, y_balanced = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "            print(\"üìä After SMOTE + Tomek:\")\n",
        "            unique_balanced, counts_balanced = np.unique(y_balanced, return_counts=True)\n",
        "            for cls, count in zip(unique_balanced, counts_balanced):\n",
        "                cls_name = class_names[cls]\n",
        "                print(f\"  {cls_name:<25} {count:,} samples\")\n",
        "\n",
        "            print(f\"‚úÖ Balanced dataset: {len(X_balanced):,} samples\")\n",
        "            return X_balanced, y_balanced\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Balancing failed: {e}\")\n",
        "            print(\"üìä Using original data with class weights in models\")\n",
        "            return X_train, y_train\n",
        "\n",
        "    elif imbalance_ratio > 2:\n",
        "        print(\"üîÑ Applying standard SMOTE...\")\n",
        "\n",
        "        try:\n",
        "            smote = SMOTE(random_state=RANDOM_STATE, k_neighbors=3)\n",
        "            X_balanced, y_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "            print(f\"‚úÖ SMOTE applied: {len(X_balanced):,} samples\")\n",
        "            return X_balanced, y_balanced\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è SMOTE failed: {e}\")\n",
        "            return X_train, y_train\n",
        "\n",
        "    else:\n",
        "        print(\"‚úÖ Classes reasonably balanced, no resampling needed\")\n",
        "        return X_train, y_train\n",
        "\n",
        "# Apply balancing\n",
        "X_train_balanced, y_train_balanced = apply_advanced_balancing(X_train_scaled, y_train)\n",
        "\n",
        "# ===============================================================================\n",
        "# CELL 13: Model Definition and Training\n",
        "# ===============================================================================\n",
        "\n",
        "def create_optimized_models():\n",
        "    \"\"\"Create highly optimized models for maximum accuracy\"\"\"\n",
        "\n",
        "    print(\"ü§ñ CREATING OPTIMIZED MODELS\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # 1. Enhanced Random Forest\n",
        "    print(\"Creating Enhanced Random Forest...\")\n",
        "    models['Enhanced_RF'] = RandomForestClassifier(\n",
        "        n_estimators=500,           # More trees\n",
        "        max_depth=25,               # Deeper trees\n",
        "        min_samples_split=2,        # More flexible splits\n",
        "        min_samples_leaf=1,         # More flexible leaves\n",
        "        max_features='sqrt',        # Good for high-dimensional data\n",
        "        bootstrap=True,\n",
        "        class_weight='balanced_subsample',  # Handle imbalance\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 2. Extra Trees (Extremely Randomized Trees)\n",
        "    print(\"Creating Extra Trees Classifier...\")\n",
        "    models['Extra_Trees'] = ExtraTreesClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=30,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features='sqrt',\n",
        "        bootstrap=False,\n",
        "        class_weight='balanced',\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 3. XGBoost\n",
        "    print(\"Creating XGBoost Classifier...\")\n",
        "    models['XGBoost'] = xgb.XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    # 4. LightGBM\n",
        "    print(\"Creating LightGBM Classifier...\")\n",
        "    models['LightGBM'] = lgb.LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=10,\n",
        "        learning_rate=0.1,\n",
        "        num_leaves=31,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Created {len(models)} optimized models\")\n",
        "    return models\n",
        "\n",
        "# Create models\n",
        "optimized_models = create_optimized_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTW6mmVx1U9h",
        "outputId": "0c9fbc72-c105-4231-d2a6-8208d8548590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ TRAINING INDIVIDUAL MODELS\n",
            "================================\n",
            "\n",
            "üìö Training Enhanced_RF...\n",
            "   ‚úÖ Enhanced_RF validation accuracy: 0.8654\n",
            "\n",
            "üìö Training Extra_Trees...\n",
            "   ‚úÖ Extra_Trees validation accuracy: 0.8531\n",
            "\n",
            "üìö Training XGBoost...\n",
            "   ‚úÖ XGBoost validation accuracy: 0.8736\n",
            "\n",
            "üìö Training LightGBM...\n",
            "   ‚úÖ LightGBM validation accuracy: 0.8791\n",
            "\n",
            "üìä INDIVIDUAL MODEL RESULTS:\n",
            "===================================\n",
            "  ‚ö†Ô∏è Enhanced_RF     0.8654\n",
            "  ‚ö†Ô∏è Extra_Trees     0.8531\n",
            "  ‚ö†Ô∏è XGBoost         0.8736\n",
            "  ‚ö†Ô∏è LightGBM        0.8791\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# CELL 14: Train Individual Models\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"üöÄ TRAINING INDIVIDUAL MODELS\")\n",
        "print(\"=\" * 32)\n",
        "\n",
        "trained_models = {}\n",
        "validation_scores = {}\n",
        "\n",
        "for name, model in optimized_models.items():\n",
        "    print(f\"\\nüìö Training {name}...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_balanced, y_train_balanced)\n",
        "    trained_models[name] = model\n",
        "\n",
        "    # Validate on validation set\n",
        "    val_pred = model.predict(X_val_scaled)\n",
        "    val_accuracy = accuracy_score(y_val, val_pred)\n",
        "    validation_scores[name] = val_accuracy\n",
        "\n",
        "    print(f\"   ‚úÖ {name} validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Check if we've reached our target\n",
        "    if val_accuracy >= 0.95:\n",
        "        print(f\"   üéâ TARGET REACHED: {val_accuracy:.4f} >= 0.95!\")\n",
        "\n",
        "print(f\"\\nüìä INDIVIDUAL MODEL RESULTS:\")\n",
        "print(\"=\" * 35)\n",
        "for name, score in validation_scores.items():\n",
        "    status = \"üéØ\" if score >= 0.95 else \"üìà\" if score >= 0.90 else \"‚ö†Ô∏è\"\n",
        "    print(f\"  {status} {name:<15} {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fndsd7Vs1Z0W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHG3aWMIfQupHOX6TgELYm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}